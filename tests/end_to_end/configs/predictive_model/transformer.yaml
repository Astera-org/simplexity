name: hooked_transformer
instance:
  _target_: transformer_lens.HookedTransformer
  cfg:
    _target_: transformer_lens.HookedTransformerConfig
    d_model: 384
    d_head: 64
    n_heads: 6
    n_layers: 1
    n_ctx: 9
    d_mlp: 1536
    d_vocab: ???
    act_fn: "relu"
    normalization_type: "LN"
    device: ${device}
    seed: ${seed}

load_checkpoint_step: null
