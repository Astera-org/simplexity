{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an end to end example of how to train a transformer on a process, probe it's internal activations for the MSP structure, and visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing all the dependencies into the .venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up all of the necessary configs for training a model #TODO: Put some explanation of all of the configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmelembroucarlitos44\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/epsilon-transformers/examples/wandb/run-20240228_044046-7rddhvg5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/melembroucarlitos44/testing-model-training/runs/7rddhvg5' target=\"_blank\">glorious-serenity-1</a></strong> to <a href='https://wandb.ai/melembroucarlitos44/testing-model-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/melembroucarlitos44/testing-model-training' target=\"_blank\">https://wandb.ai/melembroucarlitos44/testing-model-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/melembroucarlitos44/testing-model-training/runs/7rddhvg5' target=\"_blank\">https://wandb.ai/melembroucarlitos44/testing-model-training/runs/7rddhvg5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the log\n",
      "Log(train_loss=134.38645780086517, test_loss=972.6870821118355, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=128.92947083711624, test_loss=948.7941195964813, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=126.53875476121902, test_loss=945.2532307505608, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=125.87654477357864, test_loss=971.8623302578926, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=125.76160579919815, test_loss=944.0243234634399, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=124.01866745948792, test_loss=920.5150038599968, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=124.1850934624672, test_loss=926.7381775379181, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=123.69857013225555, test_loss=937.3220680952072, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=123.10215854644775, test_loss=926.9107915759087, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=123.62117046117783, test_loss=924.9313248991966, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=123.27677750587463, test_loss=921.4235506057739, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=122.75682842731476, test_loss=898.2823479175568, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=102.1532389819622, test_loss=684.6327594816685, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=82.30083790421486, test_loss=568.9200754165649, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=77.273686170578, test_loss=563.9690022468567, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=76.23820278048515, test_loss=548.1334919929504, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=76.07092833518982, test_loss=550.0219969451427, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=76.66955924034119, test_loss=563.0891780257225, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=76.04894554615021, test_loss=564.3198297321796, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=75.78689602017403, test_loss=573.0608046352863, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=75.69708368182182, test_loss=569.7417887747288, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=76.04633048176765, test_loss=563.2780140042305, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=77.14813163876534, test_loss=579.1299303472042, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=77.6442968249321, test_loss=583.9448184967041, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=77.2133119404316, test_loss=587.0619610249996, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=77.85508906841278, test_loss=586.2220247685909, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=78.78654164075851, test_loss=598.8018017411232, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=80.12051370739937, test_loss=601.1814353466034, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=80.8246876001358, test_loss=619.5789344906807, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=81.4018967449665, test_loss=609.924579679966, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=81.7417422235012, test_loss=617.4520567059517, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=83.97293040156364, test_loss=638.259169459343, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=85.00150492787361, test_loss=634.5668926239014, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=85.5927046239376, test_loss=644.7918509244919, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=87.05993968248367, test_loss=676.3970414102077, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=88.74555695056915, test_loss=667.303200751543, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=90.09509885311127, test_loss=678.571064800024, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=92.009561419487, test_loss=688.772568076849, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=93.20484772324562, test_loss=708.167240947485, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=96.53772699832916, test_loss=729.8091105818748, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=98.83884140849113, test_loss=752.2096884250641, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=103.73013973236084, test_loss=807.5770496726036, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=108.88764557242393, test_loss=839.1980063915253, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=115.84118467569351, test_loss=891.248321056366, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=120.91349893808365, test_loss=925.4723549485207, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=126.1141214966774, test_loss=961.1674471497536, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=129.20096158981323, test_loss=974.4414178133011, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=130.23205870389938, test_loss=977.5181764960289, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=130.40573859214783, test_loss=979.3558219671249, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=131.12952721118927, test_loss=984.0077474117279, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n",
      "This is the log\n",
      "Log(train_loss=0.0, test_loss=984.2908355593681, config=LoggingConfig(local=None, wandb=True, project_name='testing-model-training', train_loss=True, test_loss=True))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc89b6b01c454fa28015738bebc2fbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_loss</td><td>█▇▇█▇▇▇▇▇▇▃▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▆▇▇████</td></tr><tr><td>train_loss</td><td>████▇▇▇▇▇▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇███▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_loss</td><td>984.29084</td></tr><tr><td>train_loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-serenity-1</strong> at: <a href='https://wandb.ai/melembroucarlitos44/testing-model-training/runs/7rddhvg5' target=\"_blank\">https://wandb.ai/melembroucarlitos44/testing-model-training/runs/7rddhvg5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240228_044046-7rddhvg5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "from epsilon_transformers.training.configs import TrainConfig, RawModelConfig, OptimizerConfig, ProcessDatasetConfig, PersistanceConfig, LoggingConfig\n",
    "from epsilon_transformers.training.train import train_model\n",
    "\n",
    "\n",
    "model_config = RawModelConfig(\n",
    "            d_vocab=2,\n",
    "            d_model=100,\n",
    "            n_ctx=10,\n",
    "            d_head=48,\n",
    "            n_head=12,\n",
    "            d_mlp=12,\n",
    "            n_layers=2,\n",
    "        )\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer_type='adam',\n",
    "    learning_rate=1.06e-4,\n",
    "    weight_decay=0.8\n",
    ")\n",
    "\n",
    "dataset_config = ProcessDatasetConfig(\n",
    "    process='z1r',\n",
    "    batch_size=5,\n",
    "    num_tokens=50000,\n",
    "    test_split=0.15\n",
    ")\n",
    "\n",
    "persistance_config = PersistanceConfig(\n",
    "    location='local',\n",
    "    checkpoint_dir=pathlib.Path('/root/epsilon-transformers/temp_models'), # Temporary Hack. Don't run this in local\n",
    "    checkpoint_every_n_tokens=10000\n",
    ")\n",
    "\n",
    "mock_config = TrainConfig(\n",
    "    model=model_config,\n",
    "    optimizer=optimizer_config,\n",
    "    dataset=dataset_config,\n",
    "    persistance=persistance_config,\n",
    "    logging=LoggingConfig(project_name=\"testing-model-training\", wandb=True),\n",
    "    verbose=True,\n",
    "    seed=1337\n",
    ")\n",
    "model, metrics = train_model(mock_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have the model, we'll run the analysis on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epsilon_transformers.process.processes import ZeroOneR\n",
    "from epsilon_transformers.analysis.activation_analysis import find_msp_subspace_in_residual_stream\n",
    "\n",
    "process = ZeroOneR()\n",
    "\n",
    "ground_truth_belief_states_reshaped, predicted_beliefs = find_msp_subspace_in_residual_stream(model=model, process=process, num_sequences=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we have the subspace, we should go ahead and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epsilon_transformers.visualization.plots import generate_belief_state_figures_datashader\n",
    "\n",
    "\n",
    "fig = generate_belief_state_figures_datashader(ground_truth_tensor=ground_truth_belief_states_reshaped, predicted_beliefs=predicted_beliefs, plot_triangles=True)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
