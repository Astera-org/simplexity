# 2.2. Core Concepts

Understanding the following core concepts is crucial for effectively using and extending the Simplexity framework.

1.  **Experiments (`run_experiment.py`, `train_model.py`):**
    *   These are the primary entry points for running tasks.
    *   They orchestrate the setup, training, and (implicitly) evaluation of models.
    *   They rely heavily on the Hydra configuration system to define all aspects of the experiment.

2.  **Configuration (Hydra & YAML):**
    *   **Hydra:** The framework uses Hydra for managing complex configurations. Hydra allows for:
        *   Hierarchical configuration using YAML files.
        *   Composition of configurations from multiple files/sources.
        *   Command-line overrides for quick parameter changes.
        *   Integration with tools like Optuna for hyperparameter sweeps.
    *   **YAML Files:** Experiment settings are defined in `.yaml` files (e.g., `experiment.yaml`, `train_model.yaml`, and various component-specific configs in subdirectories of `simplexity/configs`).
    *   **Typed Configurations (`Config` dataclasses):** Python dataclasses (e.g., `simplexity.configs.config.Config`) provide structure and type safety to the configurations loaded by Hydra. The `_target_` key in config files is a Hydra convention to specify the Python class to be instantiated.

3.  **Generative Processes (`simplexity.generative_processes`):**
    *   These components are responsible for generating or providing the data sequences for training and validation.
    *   Examples seen in configurations include `mess3`, `even_ones`, etc., suggesting different types of sequence generation logic (likely Hidden Markov Models or similar, based on `build_hidden_markov_model` in configs).
    *   Each process has its own configuration (e.g., `simplexity/configs/generative_process/mess3.yaml`).

4.  **Predictive Models (`simplexity.predictive_models`):**
    *   These are the neural network models (e.g., RNNs like GRU) that learn from the data provided by the generative processes.
    *   Models are also configurable, with parameters like layer count, hidden size, etc., specified in YAML and instantiated via Hydra.
    *   The framework seems to use Equinox and Penzai (JAX-based libraries) for model building and training.

5.  **Training (`simplexity.training`):**
    *   Contains the logic for the training loop (e.g., `train_equinox_model.train`).
    *   Manages aspects like optimization, loss calculation, and interaction with data loaders.
    *   Training parameters (batch size, learning rate, number of epochs/steps) are defined in the configuration.

6.  **Logging (`simplexity.logging`):**
    *   The framework supports different logging backends (e.g., `FileLogger`, `MLFlowLogger`, `PrintLogger`).
    *   Loggers are configured via YAML and instantiated by Hydra.
    *   They record experiment configurations, parameters, metrics (like loss), and other relevant information.

7.  **Persistence (`simplexity.persistence`):**
    *   Handles saving and loading of model checkpoints.
    *   Supports different persistence backends (e.g., local file system, S3).
    *   Allows resuming training from a saved checkpoint.

8.  **Evaluation (`simplexity.evaluation`):**
    *   While not explicitly detailed in `run_experiment.py` yet, the presence of an `evaluation` directory and config suggests a dedicated component for assessing model performance on validation or test data.
    *   Validation is part of the training loop, providing metrics like validation loss.

9.  **Modularity and Extensibility:**
    *   The framework is designed with a modular structure (separate directories for models, data generators, logging, etc.).
    *   The use of Hydra and `_target_` instantiation makes it easier to add new components (e.g., a new model type or data generator) by creating a new class and a corresponding configuration file.

Understanding these concepts will help you navigate the codebase, configure experiments, and interpret their results effectively. 