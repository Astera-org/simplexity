# 1.1. Overview of the Framework

This document provides an overview of the Simplexity experimentation framework.

The framework is designed for running machine learning experiments, particularly focusing on sequence modeling tasks. It is built with Python and leverages several key libraries:

*   **Hydra:** For flexible and powerful configuration management. Experiments are configured using YAML files, allowing for easy modification of parameters, composition of configurations, and hyperparameter sweeping.
*   **Equinox:** (Likely, based on `train_equinox_model.py`) A JAX library for building and training neural networks, emphasizing functional programming and explicit state management.
*   **Penzai:** (Likely, based on `penzai_utils.py` and persister options) Another JAX-based library, potentially used for specific model architectures or utilities.
*   **Optuna:** Integrated with Hydra for hyperparameter optimization.

The core workflow involves:
1.  **Defining a Generative Process:** This component is responsible for creating training and validation data.
2.  **Defining a Predictive Model:** This is the neural network (e.g., RNN, Transformer) that will be trained to learn patterns in the data from the generative process.
3.  **Configuring the Experiment:** Using YAML files to specify the generative process, model architecture, training parameters (learning rate, batch size, epochs), logging, and persistence settings.
4.  **Running the Experiment:** Using scripts like `run_experiment.py` or `train_model.py` which parse the configuration and execute the training loop.
5.  **Logging and Persistence:** Training progress, metrics, and model checkpoints are logged and saved, allowing for reproducibility and analysis.

This framework aims to provide a structured yet flexible way to define, run, and manage machine learning experiments. 