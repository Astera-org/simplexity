# 4.2. Predictive Models

Predictive Models are the core learning components in the Simplexity framework. They are typically neural networks designed to take a sequence of observations as input and predict a distribution over the next possible observation.

## Core Interface: `PredictiveModel` Protocol

All predictive models are expected to conform to the `simplexity.predictive_models.predictive_model.PredictiveModel` protocol. This is a structural interface (defined using `typing.Protocol`) that requires any model class to have a specific `__call__` method:

```python
from typing import Protocol, runtime_checkable
import jax

@runtime_checkable
class PredictiveModel(Protocol):
    """A predictive model that takes observations and returns a logit distribution over observations."""

    def __call__(self, x: jax.Array, /) -> jax.Array:
        """Predict the next state given the current state."""
        ...
```

*   The `__call__` method must accept a JAX array `x` (representing a batch of input sequences or a single sequence) and return a JAX array (typically representing the logits of the probability distribution over the vocabulary for the next observation in the sequence(s)).
*   Models are generally implemented as `equinox.Module` subclasses to integrate with Equinox's functional JAX patterns for state management and transformations (like `jax.grad`, `jax.jit`).

## Example Implementation: `GRURNN`

A concrete example provided in the framework is `simplexity.predictive_models.gru_rnn.GRURNN`. This model is a Gated Recurrent Unit (GRU) based Recurrent Neural Network.

*   **Structure:** It consists of one or more GRU layers followed by a final linear layer to map the GRU outputs to the vocabulary size (logits).
    *   `GRUFn`: A helper module that wraps `equinox.nn.GRUCell` to process sequences using `jax.lax.scan`.
    *   `LinearFn`: A helper module that wraps `equinox.nn.Linear` to process sequences, applying the linear transformation element-wise.
    *   `GRURNN`: The main module that stacks these layers using `equinox.nn.Sequential`.
*   **Initialization:** The `GRURNN` is initialized with input size, output size (both typically `vocab_size`), a sequence of hidden sizes for the GRU layers, and a JAX PRNG key for weight initialization.

## Configuration and Building

Predictive models are configured via YAML files, typically found in `simplexity/configs/predictive_model/`. For example, `gru_rnn.yaml` configures the `GRURNN` model.

An example configuration snippet for `gru_rnn`:
```yaml
# In simplexity/configs/predictive_model/gru_rnn.yaml
_target_: simplexity.predictive_models.gru_rnn.build_gru_rnn
# vocab_size: is typically injected or already known by the runner script
num_layers: 2
hidden_size: 64
seed: 42
```

Key points:
*   `_target_`: This Hydra key points to a builder function, in this case, `simplexity.predictive_models.gru_rnn.build_gru_rnn`.
*   Parameters like `num_layers`, `hidden_size`, and `seed` are passed to this builder function.
*   The `vocab_size` is a crucial parameter. While it might be specified here, it's often determined from the `training_data_generator` and passed programmatically to the builder function by the main experiment script (`run_experiment.py`). The `build_gru_rnn` function expects `vocab_size` as its first argument.

The builder function (`build_gru_rnn`) then instantiates the `GRURNN` model with the appropriate parameters and JAX key.

## How Models Are Used in Experiments

1.  During experiment setup in `run_experiment.py`:
    *   Hydra loads the configuration for `predictive_model`.
    *   It calls the specified `_target_` builder function (e.g., `build_gru_rnn`), passing in parameters from the YAML and the `vocab_size` obtained from the instantiated `training_data_generator`.
    *   This creates an instance of the model (e.g., `GRURNN`).
2.  This model instance is then passed to the training function (e.g., `simplexity.training.train_equinox_model.train`).
3.  The training loop repeatedly calls the model with batches of data to get predictions, computes loss, and updates the model's parameters using `equinox.apply_updates` and an optimizer like Optax.

## For Experimentalists

*   **Selecting a Model:** Change the `predictive_model` default in `experiment.yaml` to point to a different model configuration file (e.g., if you had `my_transformer.yaml`, you'd use `predictive_model: my_transformer`).
*   **Changing Model Architecture:** Modify parameters within the model's YAML config file (e.g., `simplexity/configs/predictive_model/gru_rnn.yaml` to change `num_layers` or `hidden_size`) or override them via the command line:
    ```bash
    python simplexity/run_experiment.py predictive_model.instance.num_layers=3 predictive_model.instance.hidden_size=128
    ```
    *(Note: The `.instance` part is often present because the main `predictive_model` config might have a nested structure, like `instance: { _target_: ..., num_layers: ... }`)*

## For LLM Agents

*   Agents can define the model by modifying the `predictive_model` section in the main `experiment.yaml` or by creating/editing YAML files in `simplexity/configs/predictive_model/`.
*   The key is to ensure the `_target_` points to a valid builder function and that all required arguments for that builder (like `vocab_size`, `num_layers`, `hidden_size`, `seed` for `build_gru_rnn`) are provided either in the YAML or can be inferred/passed by the calling script.
*   To understand parameters for a new model type, an agent would need to inspect its builder function signature and its `__init__` method if it's an `eqx.Module`. 