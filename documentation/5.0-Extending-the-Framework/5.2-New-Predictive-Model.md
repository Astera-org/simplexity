# 5.2. Adding New Predictive Models

The Simplexity framework allows for the integration of new predictive model architectures. If you want to experiment with a novel type of RNN, Transformer, or other sequence model, follow these steps.

## 1. Understand the `PredictiveModel` Protocol

Any new predictive model must conform to the `simplexity.predictive_models.predictive_model.PredictiveModel` protocol. This means it must be a callable object (typically an `equinox.Module` subclass) with a `__call__` method matching this signature:

```python
def __call__(self, x: jax.Array, /) -> jax.Array:
    # x: input sequence (batch_size, sequence_len, feature_size) or similar
    # returns: logits (batch_size, sequence_len, vocab_size)
    ...
```

## 2. Choose Your Integration Approach

There are two main approaches to integrating models:

### Approach A: Direct Library Instantiation (Recommended for External Libraries)

If you're using an existing library (like Penzai, Flax, etc.) that already provides model builder functions, you can use them directly without creating wrapper functions. This is the cleanest and most maintainable approach.

**Example using Penzai's LLaMA-like transformer:**

```yaml
name: transformer
instance:
  _target_: penzai.models.transformer.variants.llamalike_common.build_llamalike_transformer
  config:
    _target_: penzai.models.transformer.variants.llamalike_common.LlamalikeTransformerConfig
    num_kv_heads: 2
    query_head_multiplier: 2
    embedding_dim: 16
    projection_dim: 16
    mlp_hidden_dim: 16
    num_decoder_blocks: 2
    vocab_size: ${training_data_generator.vocab_size}
    mlp_variant: geglu_approx
    tie_embedder_and_logits: false
    # Advanced parameters
    rope_wavelength: 10000
    rms_norm_eps: 1e-06
    attention_type:
      _target_: penzai.models.transformer.variants.llamalike_common.AttentionTypeGlobalCausal
    use_post_attn_norm: false
    use_post_ffw_norm: false
    final_logit_softcap: null
    attn_logits_soft_cap: null
    query_scaling_factor: default
    parameter_dtype:
      _target_: jax.numpy.dtype
      _args_:
        - float32
    activation_dtype:
      _target_: jax.numpy.dtype
      _args_:
        - float32
    use_layer_stack: false
  init_base_rng:
    _target_: jax.random.PRNGKey
    seed: ${seed}
  name: transformer

load_checkpoint_step:
```

**Key advantages:**
- No custom Python code needed
- Full access to all library parameters
- Hydra handles complex object instantiation (config objects, JAX types, etc.)
- More maintainable (no wrapper functions to update when library changes)

**How it works:**
1. Hydra instantiates the inner `config` object using the specified `_target_`
2. Hydra converts `seed` to a JAX PRNGKey using `jax.random.PRNGKey`
3. Hydra calls the main `_target_` function with the instantiated objects
4. The model is ready to use

### Approach B: Custom Implementation or Wrapper Functions

Use this approach when:
- You're implementing a completely new model from scratch
- You need custom preprocessing/postprocessing logic
- The external library's interface doesn't fit well with Hydra

## 3. Implement Your Model Class (Only for Approach B)

Create a new Python file for your model, for example, `simplexity/predictive_models/my_custom_model.py`.

```python
# In simplexity/predictive_models/my_custom_model.py
import equinox as eqx
import jax
import jax.numpy as jnp
from simplexity.predictive_models.predictive_model import PredictiveModel # To indicate conformance

class MyCustomModel(eqx.Module): # Conforms to PredictiveModel implicitly
    # Define layers and parameters as eqx.Module attributes
    # Example: a simple linear model for illustration
    linear_layer: eqx.nn.Linear
    vocab_size: int = eqx.field(static=True)

    def __init__(self, in_features: int, vocab_size: int, *, key: jax.PRNGKey):
        self.vocab_size = vocab_size
        self.linear_layer = eqx.nn.Linear(in_features, vocab_size, key=key)

    def __call__(self, x: jax.Array) -> jax.Array:
        # Apply layers to the input sequence x
        # For many sequence models, you might use jax.lax.scan or eqx.nn.Sequential
        # Example: apply linear layer to each element in the sequence
        return jax.vmap(self.linear_layer)(x)

# Make sure your model handles batches and sequences appropriately.
# The GRURNN model uses helper eqx.nn.Lambda with internal jax.lax.scan for sequence processing.
```

**Key Considerations:**
*   **Equinox Module:** Your model should ideally be an `equinox.Module` for compatibility with JAX transformations (`jax.grad`, `jax.jit`) and Equinox utilities (serialization, `eqx.apply_updates`).
*   **Parameters:** Model parameters (weights, biases) should be attributes that are JAX arrays. Non-trainable attributes (like layer sizes, activation functions if they are types/functions) should be marked with `eqx.field(static=True)` if they are part of the PyTree definition but shouldn't be differentiated or serialized as arrays.
*   **JAX PRNGKey:** Accept a `jax.PRNGKey` in your `__init__` for initializing parameters to ensure reproducibility.
*   **Input/Output Shapes:** Ensure your `__call__` method handles the expected input shapes (often `(batch_size, sequence_len, feature_dim)` for one-hot inputs) and produces logits of shape `(batch_size, sequence_len, vocab_size)`.

## 4. Create a Builder Function (Recommended)

To integrate smoothly with Hydra and simplify instantiation, create a builder function for your model. This function will typically reside in the same file as your model or in a dedicated `builder.py` within `simplexity/predictive_models/`.

```python
# In simplexity/predictive_models/my_custom_model.py (continued)

def build_my_custom_model(vocab_size: int, in_features: int, another_param: str, seed: int) -> MyCustomModel:
    key = jax.random.PRNGKey(seed)
    # Process another_param if needed
    print(f"Building MyCustomModel with in_features={in_features}, vocab_size={vocab_size}, seed={seed}, extra_param='{another_param}'")
    return MyCustomModel(in_features=in_features, vocab_size=vocab_size, key=key)
```
*   The `vocab_size` is often a critical parameter that the main experiment script (`run_experiment.py`) derives from the data generator and passes to the model builder.
*   The `seed` is used to generate the JAX PRNG key.

## 5. Create a Configuration YAML File

Add a new YAML configuration file for your model in the `simplexity/configs/predictive_model/` directory.

*   **File:** `simplexity/configs/predictive_model/my_custom_model.yaml`

*   **Content:**
    ```yaml
    # _target_ should point to your new config dataclass (see step 5) or be directly used by the main PredictiveModel config
    # For the builder pattern, the instance._target_ is key:
    _target_: simplexity.configs.predictive_model.config.ModelInstanceConfig # Or a more specific one if you define it
    # The actual instance of your model will be created by this _target_:
    # This should match the path to your builder function:
    # _target_: simplexity.predictive_models.my_custom_model.build_my_custom_model
    
    # Parameters for your builder function (build_my_custom_model)
    # vocab_size: will be injected by run_experiment.py
    in_features: 50 # Example parameter, adjust as per your model
    another_param: "hello_world"
    seed: 42 # Default seed for the model

    # This name is used to select the model in experiment.yaml
    # It's part of the outer Config structure for predictive_model, not the instance itself.
    # name: "my_custom_model" # This would be in the main Config for the model group
    ```
    More precisely, the main configuration structure for `predictive_model` (e.g. `simplexity.configs.predictive_model.config.Config`) usually has an `instance` field of type `ModelInstanceConfig`. Your `my_custom_model.yaml` would define values for an instance of `ModelInstanceConfig`, with its `_target_` pointing to your `build_my_custom_model`.

    Example `simplexity/configs/predictive_model/my_custom_model.yaml`:
    ```yaml
    # This file defines one choice for the 'predictive_model' config group
    instance:
      _target_: simplexity.predictive_models.my_custom_model.build_my_custom_model
      # vocab_size: will be injected by run_experiment.py from the data generator
      in_features: 50 # Example parameter, adjust as per your model
      another_param: "hello_world"
      seed: 42 # Default seed for the model

    name: "my_custom_model" # Name used to select this config
    load_checkpoint_step: 0 # Default, can be overridden
    ```

## 6. (Optional) Define a Custom Dataclass for ModelInstanceConfig

For better structure, especially if your model has many specific parameters for its `instance` configuration, you can define a new dataclass inheriting from `simplexity.configs.predictive_model.config.ModelInstanceConfig`.

```python
# In simplexity/configs/predictive_model/config.py

@dataclass
class MyCustomModelInstanceConfig(ModelInstanceConfig):
    _target_: Literal["simplexity.predictive_models.my_custom_model.build_my_custom_model"] = (
        "simplexity.predictive_models.my_custom_model.build_my_custom_model"
    )
    in_features: int
    another_param: str
    # vocab_size is inherited from ModelInstanceConfig and filled at runtime
    # seed is also often part of the base or filled globally
```
If you do this, your `my_custom_model.yaml` would then have `_target_: simplexity.configs.predictive_model.config.MyCustomModelInstanceConfig` at the top level of the `instance:` block, or the main `predictive_model` config would have its `instance` field typed as a `Union` including `MyCustomModelInstanceConfig`.

## 7. Use Your New Model

In your main experiment YAML (e.g., `experiment.yaml`), change the `predictive_model` default to select your new model's configuration file name:

```yaml
defaults:
  # ...
  - predictive_model: my_custom_model # This refers to my_custom_model.yaml
  # ...
```

When `run_experiment.py` is executed:
1.  Hydra loads `simplexity/configs/predictive_model/my_custom_model.yaml` for the `predictive_model` group.
2.  The `vocab_size` from the data generator is obtained.
3.  The `predictive_model.instance._target_` (i.e., `build_my_custom_model`) is called with parameters from the YAML (`in_features`, `another_param`, `seed`) and the programmatically supplied `vocab_size`.
4.  Your custom model is instantiated and used in the training loop.

Remember to ensure your model interacts correctly with the training loop in `simplexity.training.train_equinox_model.py` (or a custom one if needed), especially regarding how it processes data batches and how its loss is computed. 