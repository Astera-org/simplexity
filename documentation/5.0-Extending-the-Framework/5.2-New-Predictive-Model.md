# 5.2. Adding New Predictive Models

The Simplexity framework allows for the integration of new predictive model architectures. If you want to experiment with a novel type of RNN, Transformer, or other sequence model, follow these steps.

## 1. Understand the `PredictiveModel` Protocol

Any new predictive model must conform to the `simplexity.predictive_models.predictive_model.PredictiveModel` protocol. This means it must be a callable object (typically an `equinox.Module` subclass) with a `__call__` method matching this signature:

```python
def __call__(self, x: jax.Array, /) -> jax.Array:
    # x: input sequence (batch_size, sequence_len, feature_size) or similar
    # returns: logits (batch_size, sequence_len, vocab_size)
    ...
```

## 2. Implement Your Model Class

Create a new Python file for your model, for example, `simplexity/predictive_models/my_custom_model.py`.

```python
# In simplexity/predictive_models/my_custom_model.py
import equinox as eqx
import jax
import jax.numpy as jnp
from simplexity.predictive_models.predictive_model import PredictiveModel # To indicate conformance

class MyCustomModel(eqx.Module): # Conforms to PredictiveModel implicitly
    # Define layers and parameters as eqx.Module attributes
    # Example: a simple linear model for illustration
    linear_layer: eqx.nn.Linear
    vocab_size: int = eqx.field(static=True)

    def __init__(self, in_features: int, vocab_size: int, *, key: jax.PRNGKey):
        self.vocab_size = vocab_size
        self.linear_layer = eqx.nn.Linear(in_features, vocab_size, key=key)

    def __call__(self, x: jax.Array) -> jax.Array:
        # Apply layers to the input sequence x
        # For many sequence models, you might use jax.lax.scan or eqx.nn.Sequential
        # Example: apply linear layer to each element in the sequence
        return jax.vmap(self.linear_layer)(x)

# Make sure your model handles batches and sequences appropriately.
# The GRURNN model uses helper eqx.nn.Lambda with internal jax.lax.scan for sequence processing.
```

**Key Considerations:**
*   **Equinox Module:** Your model should ideally be an `equinox.Module` for compatibility with JAX transformations (`jax.grad`, `jax.jit`) and Equinox utilities (serialization, `eqx.apply_updates`).
*   **Parameters:** Model parameters (weights, biases) should be attributes that are JAX arrays. Non-trainable attributes (like layer sizes, activation functions if they are types/functions) should be marked with `eqx.field(static=True)` if they are part of the PyTree definition but shouldn't be differentiated or serialized as arrays.
*   **JAX PRNGKey:** Accept a `jax.PRNGKey` in your `__init__` for initializing parameters to ensure reproducibility.
*   **Input/Output Shapes:** Ensure your `__call__` method handles the expected input shapes (often `(batch_size, sequence_len, feature_dim)` for one-hot inputs) and produces logits of shape `(batch_size, sequence_len, vocab_size)`.

## 3. Create a Builder Function (Recommended)

To integrate smoothly with Hydra and simplify instantiation, create a builder function for your model. This function will typically reside in the same file as your model or in a dedicated `builder.py` within `simplexity/predictive_models/`.

```python
# In simplexity/predictive_models/my_custom_model.py (continued)

def build_my_custom_model(vocab_size: int, in_features: int, another_param: str, seed: int) -> MyCustomModel:
    key = jax.random.PRNGKey(seed)
    # Process another_param if needed
    print(f"Building MyCustomModel with in_features={in_features}, vocab_size={vocab_size}, seed={seed}, extra_param='{another_param}'")
    return MyCustomModel(in_features=in_features, vocab_size=vocab_size, key=key)
```
*   The `vocab_size` is often a critical parameter that the main experiment script (`run_experiment.py`) derives from the data generator and passes to the model builder.
*   The `seed` is used to generate the JAX PRNG key.

## 4. Create a Configuration YAML File

Add a new YAML configuration file for your model in the `simplexity/configs/predictive_model/` directory.

*   **File:** `simplexity/configs/predictive_model/my_custom_model.yaml`

*   **Content:**
    ```yaml
    # _target_ should point to your new config dataclass (see step 5) or be directly used by the main PredictiveModel config
    # For the builder pattern, the instance._target_ is key:
    _target_: simplexity.configs.predictive_model.config.ModelInstanceConfig # Or a more specific one if you define it
    # The actual instance of your model will be created by this _target_:
    # This should match the path to your builder function:
    # _target_: simplexity.predictive_models.my_custom_model.build_my_custom_model
    
    # Parameters for your builder function (build_my_custom_model)
    # vocab_size: will be injected by run_experiment.py
    in_features: 50 # Example parameter, adjust as per your model
    another_param: "hello_world"
    seed: 42 # Default seed for the model

    # This name is used to select the model in experiment.yaml
    # It's part of the outer Config structure for predictive_model, not the instance itself.
    # name: "my_custom_model" # This would be in the main Config for the model group
    ```
    More precisely, the main configuration structure for `predictive_model` (e.g. `simplexity.configs.predictive_model.config.Config`) usually has an `instance` field of type `ModelInstanceConfig`. Your `my_custom_model.yaml` would define values for an instance of `ModelInstanceConfig`, with its `_target_` pointing to your `build_my_custom_model`.

    Example `simplexity/configs/predictive_model/my_custom_model.yaml`:
    ```yaml
    # This file defines one choice for the 'predictive_model' config group
    instance:
      _target_: simplexity.predictive_models.my_custom_model.build_my_custom_model
      # vocab_size: will be injected by run_experiment.py from the data generator
      in_features: 50 # Example parameter, adjust as per your model
      another_param: "hello_world"
      seed: 42 # Default seed for the model

    name: "my_custom_model" # Name used to select this config
    load_checkpoint_step: 0 # Default, can be overridden
    ```

## 5. (Optional) Define a Custom Dataclass for ModelInstanceConfig

For better structure, especially if your model has many specific parameters for its `instance` configuration, you can define a new dataclass inheriting from `simplexity.configs.predictive_model.config.ModelInstanceConfig`.

```python
# In simplexity/configs/predictive_model/config.py

@dataclass
class MyCustomModelInstanceConfig(ModelInstanceConfig):
    _target_: Literal["simplexity.predictive_models.my_custom_model.build_my_custom_model"] = (
        "simplexity.predictive_models.my_custom_model.build_my_custom_model"
    )
    in_features: int
    another_param: str
    # vocab_size is inherited from ModelInstanceConfig and filled at runtime
    # seed is also often part of the base or filled globally
```
If you do this, your `my_custom_model.yaml` would then have `_target_: simplexity.configs.predictive_model.config.MyCustomModelInstanceConfig` at the top level of the `instance:` block, or the main `predictive_model` config would have its `instance` field typed as a `Union` including `MyCustomModelInstanceConfig`.

## 6. Use Your New Model

In your main experiment YAML (e.g., `experiment.yaml`), change the `predictive_model` default to select your new model's configuration file name:

```yaml
defaults:
  # ...
  - predictive_model: my_custom_model # This refers to my_custom_model.yaml
  # ...
```

When `run_experiment.py` is executed:
1.  Hydra loads `simplexity/configs/predictive_model/my_custom_model.yaml` for the `predictive_model` group.
2.  The `vocab_size` from the data generator is obtained.
3.  The `predictive_model.instance._target_` (i.e., `build_my_custom_model`) is called with parameters from the YAML (`in_features`, `another_param`, `seed`) and the programmatically supplied `vocab_size`.
4.  Your custom model is instantiated and used in the training loop.

Remember to ensure your model interacts correctly with the training loop in `simplexity.training.train_equinox_model.py` (or a custom one if needed), especially regarding how it processes data batches and how its loss is computed. 