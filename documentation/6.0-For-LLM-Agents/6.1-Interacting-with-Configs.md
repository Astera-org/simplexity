# 6.1. Interacting with Configuration Files

LLM (Large Language Model) coding agents will primarily interact with the Simplexity framework by reading, understanding, and modifying Hydra configuration (YAML) files. Here's a guide for agents on how to do this effectively.

## Understanding the Configuration Structure

1.  **Main Entry Point:** The primary configuration file for an experiment is typically `simplexity/configs/experiment.yaml` (or `simplexity/configs/train_model.yaml`).

2.  **Defaults and Composition:** Pay close attention to the `defaults` list at the top of `experiment.yaml`. This list dictates how the final configuration is composed from various sub-configuration files (config groups).
    *   Example: `- predictive_model: gru_rnn` means that the settings for the `predictive_model` part of the configuration are loaded from `simplexity/configs/predictive_model/gru_rnn.yaml`.
    *   An agent needs to trace these defaults to find the specific file controlling a particular component.

3.  **Component Configuration Files:** Located in subdirectories of `simplexity/configs/` (e.g., `generative_process/`, `predictive_model/`, `train/`, `optimizer/`, `logging/`, `persistence/`, `evaluation/`).
    *   Each file in these directories usually represents a specific choice for that component (e.g., `gru_rnn.yaml` for the GRU model, `adamw.yaml` for the AdamW optimizer).

4.  **Python Dataclasses (Schemas):** The structure of these YAML files is mirrored by Python dataclasses in `simplexity/configs/` (e.g., `simplexity.configs.config.Config`, `simplexity.configs.predictive_model.config.Config` and `ModelInstanceConfig`).
    *   These dataclasses define the expected fields, types, and default values.
    *   The `_target_` key in YAML is crucial: it specifies the Python class or builder function to be instantiated by Hydra using the subsequent parameters in that YAML block.

## Key Tasks for LLM Agents

1.  **Reading/Understanding Current Configuration:**
    *   To understand the full configuration for a default run of `python simplexity/run_experiment.py`, an agent would need to:
        1.  Start with `simplexity/configs/experiment.yaml`.
        2.  Recursively resolve all entries in the `defaults` list to read the content of the included YAML files.
        3.  Merge these according to Hydra's rules (later entries in `defaults` can override earlier ones, and specific settings override defaults from groups).
    *   Hydra also provides a command to print the fully resolved configuration: `python simplexity/run_experiment.py --cfg job`.

2.  **Modifying Experiment Parameters:**
    *   **Changing a component choice:** To switch from a GRU model to a different model (e.g., `my_lstm.yaml`), the agent should modify the `defaults` list in `experiment.yaml`:
        ```diff
        defaults:
          - _self_
          - generative_process@training_data_generator: mess3
          - generative_process@validation_data_generator: mess3
        - - predictive_model: gru_rnn
        + - predictive_model: my_lstm # Assuming my_lstm.yaml exists
          - persistence: local_persister
          # ...
        ```
    *   **Modifying parameters of a chosen component:** To change `hidden_size` for the `gru_rnn` model, the agent should modify `simplexity/configs/predictive_model/gru_rnn.yaml` (specifically the `instance.hidden_size` field) or the relevant section if it's directly in `experiment.yaml` due to an override or direct definition.
        ```yaml
        # In simplexity/configs/predictive_model/gru_rnn.yaml
        instance:
          _target_: simplexity.predictive_models.gru_rnn.build_gru_rnn
          hidden_size: 128 # Change this value
          num_layers: 2
          seed: ${seed} # Often references a global seed
        # ...
        ```
    *   **Modifying top-level parameters in `experiment.yaml`:** Parameters like `seed`, `experiment_name`, or sweep parameters under `hydra.sweeper.params` can be directly modified in `experiment.yaml`.

3.  **Setting up Hyperparameter Sweeps:**
    *   Modify the `hydra.sweeper.params` section in `experiment.yaml`.
    *   The keys are dot-separated paths to the parameters in the fully resolved configuration (e.g., `train.optimizer.instance.learning_rate`, `predictive_model.instance.hidden_size`).
    *   The values define the search space using Optuna/Hydra syntax (e.g., `choice(16, 32, 64)`, `tag(log, interval(1e-4, 1e-1))`).

4.  **Creating New Configuration Files for New Components:**
    *   When adding a new model or data generator (as per Section 5), the agent will need to create new YAML files in the appropriate `simplexity/configs/<component_group>/` directory.
    *   These files must specify the `_target_` (pointing to the component's class or builder function) and any necessary parameters for that component.

## Important Considerations for Agents

*   **YAML Syntax:** Ensure valid YAML syntax. Use a YAML parser/linter if possible when generating modifications.
*   **`_target_` Paths:** The `_target_` paths must be correct fully qualified Python paths to classes or functions that Hydra can import and call.
*   **Parameter Matching:** Parameters provided in the YAML for a `_target_` must match the arguments (and their types, if type-checked by Hydra/Pydantic) of the target class's `__init__` method or the builder function.
*   **Variable Interpolation:** Hydra supports variable interpolation (e.g., `${seed}`, `${predictive_model.name}`). Agents should be aware of this and preserve or correctly use interpolations.
*   **Command-Line Overrides vs. File Changes:** While agents can *simulate* command-line overrides by modifying files, for persistent changes, modifying the YAML files is the standard approach. The documentation on `run_experiment_script.md` details how command-line overrides are structured, which can inform an agent how to achieve the same effect by changing the correct YAML field.
*   **Idempotency:** If an agent is asked to make a change that's already been made, it should ideally recognize this and not re-apply it or report that the state is already as requested.

By understanding these patterns, an LLM agent can effectively manage and configure experiments within the Simplexity framework. 