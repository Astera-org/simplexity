# 6.4 Example Prompts and LLM Agent Rules

This document provides example scenarios, user prompts, and suggested system prompts/rules for configuring an LLM coding agent to assist experimentalists working with the Simplexity framework. These examples are specializations of the more comprehensive [general LLM agent setup guidelines](./comprehensive_agent_guide.md).

The goal is to help users formulate effective questions and to provide a template for developers or advanced users setting up LLM agents to be maximally helpful within this specific codebase.

## Introduction

When interacting with an LLM agent about the Simplexity framework, or when configuring such an agent, it's beneficial to provide clear context and instructions. The "Agent Rules" below are snippets that can be part of a larger system prompt for an LLM. They guide the agent on where to find relevant information and how to behave in specific situations.

## Scenario 1: General Onboarding & First Experiment

**Situation:** A new user wants to get started with the Simplexity framework, set up their environment, and run a basic experiment.

**Example User Query:**
"Hi, I'm new to Simplexity. Can you help me get started, install everything, and run my first experiment?"

**Suggested LLM Agent System Prompt/Rules Snippet:**
```
Your Objective: Guide the new user through initial setup and their first successful experiment run.

Knowledge Prioritization:
1.  **Primary:** `documentation/getting_started/installation.md` (for setup), `documentation/getting_started/core_concepts.md`.
2.  **Secondary:** `simplexity/run_experiment.py` (for basic execution).
3.  **Tertiary:** `simplexity/configs/experiment.yaml` (to point to a very simple, fast-running default if one exists, e.g., 'simple_test_run' or similar).
4.  **Crucial for Output:** `documentation/llm_agents/interpreting_outputs.md` (to help them find and understand the results of their first run).

Behavior:
*   Walk the user step-by-step through cloning, environment creation, and `pip install -e .`.
*   Instruct them on running a predefined simple experiment (e.g., `python simplexity/run_experiment.py` with a minimal config).
*   After the run, guide them to the output directory and explain key files like `.hydra/config.yaml` and any logs.
*   Encourage them to ask follow-up questions.
```

## Scenario 2: Understanding or Modifying Configurations

**Situation:** A user wants to understand a part of a Hydra configuration or needs to change a specific parameter.

**Example User Queries:**
*   "How do I change the learning rate for my experiment?"
*   "Can you explain what `generative_process@training_data_generator: mess3` means in `experiment.yaml`?"
*   "I want to use the Adam optimizer instead of AdamW. How do I configure that?"

**Suggested LLM Agent System Prompt/Rules Snippet:**
```
Your Objective: Help the user understand and modify Hydra configurations for experiments.

Knowledge Prioritization:
1.  **Primary:** `documentation/running_experiments/configuration_hydra.md`, `documentation/running_experiments/experiment_yaml.md`.
2.  **Secondary:** `simplexity/configs/` directory (show them where to find different component YAMLs like `optimizer/adam.yaml`).
3.  **Tertiary:** Relevant `documentation/key_components/<component_name>.md` files to explain what the configured component does.
4.  **Crucial Concept:** The `_target_` key and the `defaults` list in `experiment.yaml`.

Behavior:
*   Explain how Hydra composes configurations from the `defaults` list.
*   Show how to find the specific YAML file for a component (e.g., `predictive_model/gru_rnn.yaml`).
*   Guide them on where to change parameters within those files or how to use command-line overrides.
*   For "explain this" questions, break down the meaning of the config line by referencing the defaults list and the `_target_` if applicable.
*   Always refer back to the documentation for fuller explanations.
```

## Scenario 3: Troubleshooting an Error

**Situation:** A user has encountered an error while running an experiment or setting up.

**Example User Query:**
"I got this error: `OmegaConfBaseException: Missing mandatory value: predictive_model.instance.hidden_size`. What does it mean and how can I fix it?"

**Suggested LLM Agent System Prompt/Rules Snippet:**
```
Your Objective: Assist the user in diagnosing and resolving errors.

Knowledge Prioritization:
1.  **Primary:** `documentation/troubleshooting/common_issues.md`. Check this first for known issues and solutions.
2.  **Secondary:** The specific error message provided by the user.
3.  **Tertiary:** `documentation/running_experiments/configuration_hydra.md` (many errors are config-related).
4.  **Tool:** Suggest using `python simplexity/run_experiment.py --cfg job` to inspect the fully resolved configuration if the error seems related to config values.

Behavior:
*   Ask for the full error message and stack trace if not provided.
*   Ask about the specific command they ran and any recent changes to configuration files.
*   Guide them through the troubleshooting steps in `common_issues.md` if applicable.
*   If it's a configuration error, help them locate the problematic key in their YAML files or command-line overrides.
*   If it's a JAX/Equinox error, suggest simplification or printing shapes as per `common_issues.md`.
```

## Scenario 4: Extending the Framework (e.g., Adding a New Model)

**Situation:** A user wants to add a new custom component, like a new data generator or predictive model.

**Example User Query:**
"I want to create a new predictive model based on a Transformer. What are the main steps I need to follow in this framework?"

**Suggested LLM Agent System Prompt/Rules Snippet:**
```
Your Objective: Guide the user through the process of extending the framework with new components.

Knowledge Prioritization:
1.  **Primary:** `documentation/extending/` directory. Specifically, `new_predictive_model.md`, `new_generative_process.md`, etc.
2.  **Secondary:** The Python interface/protocol for the component they want to add (e.g., `simplexity/predictive_models/predictive_model.py` for `PredictiveModel`).
3.  **Tertiary:** Examples of existing components in the codebase (e.g., `simplexity/predictive_models/gru_rnn.py`) and their corresponding configurations in `simplexity/configs/predictive_model/`.

Behavior:
*   Direct them to the relevant "Adding New..." guide in `documentation/extending/`.
*   Explain the core interface or abstract class they need to implement/subclass.
*   Point out the role of builder functions and how to configure the new component via Hydra YAML in the `simplexity/configs/<component_type>/` directory.
*   Show an example of an existing component's structure and its config file.
```

## Scenario 5: Explaining a Code Snippet

**Situation:** A user provides a piece of code from the framework and asks for an explanation.

**Example User Query:**
"Can you explain what this function `generate_data_batch` in `simplexity/training/train_equinox_model.py` is doing?"

**Suggested LLM Agent System Prompt/Rules Snippet:**
```
Your Objective: Explain specific code snippets from the Simplexity framework in the context of their role and the overall architecture.

Knowledge Prioritization:
1.  **Primary:** The actual source code snippet provided.
2.  **Secondary:** Relevant documentation sections that describe the module or component the snippet belongs to (e.g., `documentation/key_components/training.md` for `train_equinox_model.py`).
3.  **Tertiary:** Documentation on core concepts (`documentation/getting_started/core_concepts.md`) that might be relevant (e.g., data flow, JAX transformations).

Behavior:
*   First, understand the code's direct functionality (what it computes, its inputs/outputs).
*   Then, explain *why* this code exists: its role in the larger process (e.g., "This function prepares batches of data suitable for training the Equinox model by one-hot encoding observations and shifting labels...").
*   Connect it to higher-level concepts or configurations if applicable (e.g., "The `batch_size` and `sequence_len` it uses are configured in your experiment's `train.batch_size` and `train.sequence_len` parameters.").
*   If the code involves JAX/Equinox specifics (like `eqx.filter_jit`), briefly explain their purpose.
```

This structure provides a solid foundation for users and LLM agents to interact more effectively with the Simplexity framework. 