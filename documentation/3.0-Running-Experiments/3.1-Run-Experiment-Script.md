# 3.1. Using `run_experiment.py`

The primary script for launching experiments is `simplexity/run_experiment.py`. This script uses Hydra to manage configurations and orchestrate the various components of an experiment.

## Basic Usage

To run an experiment with the default configuration (as defined in `simplexity/configs/experiment.yaml` and its defaults), navigate to the root directory of the project and execute:

```bash
python simplexity/run_experiment.py
```

This will:
1.  Load the configuration specified in `simplexity/configs/experiment.yaml`.
2.  Instantiate the necessary components (data generators, model, logger, persister) based on this configuration.
3.  If a `load_checkpoint_step` is specified in the model config and a checkpoint exists, it will load the model weights.
4.  Execute the training process.
5.  Log results and save model checkpoints according to the logging and persistence configurations.
6.  Output the final loss value.

## Overriding Configuration Parameters

Hydra allows you to override any configuration parameter directly from the command line. This is extremely useful for quick iterations and launching multiple variations of an experiment without modifying YAML files.

**Syntax:** `python simplexity/run_experiment.py <group>.<parameter>=<value>`

**Examples:**

*   **Change the learning rate:**
    ```bash
    python simplexity/run_experiment.py training.optimizer.instance.learning_rate=0.0005
    ```

*   **Change the number of training steps:**
    ```bash
    python simplexity/run_experiment.py training.num_train_steps=50000
    ```

*   **Use a different training data generator (assuming `my_custom_data.yaml` exists in `simplexity/configs/generative_process`):**
    ```bash
    python simplexity/run_experiment.py training_data_generator=my_custom_data
    ```
    (Note: `my_custom_data` here refers to the filename without the `.yaml` extension, and it should define a configuration compatible with `DataGeneratorConfig`.)

*   **Change the predictive model's hidden size:**
    ```bash
    python simplexity/run_experiment.py predictive_model.instance.hidden_size=128
    ```

*   **Run with a different seed:**
    ```bash
    python simplexity/run_experiment.py seed=42
    ```

## Multi-run for Sweeps

Hydra also supports launching multiple runs with different parameter combinations, which is essential for hyperparameter sweeps. This is typically configured in `experiment.yaml` (or a sweeper config) but can also be invoked from the command line.

```bash
python simplexity/run_experiment.py --multirun <param_to_sweep>=<value1>,<value2> <another_param>=<value_a>,<value_b>
```

**Example:** Sweep over learning rates and batch sizes:
```bash
python simplexity/run_experiment.py --multirun training.optimizer.instance.learning_rate=0.01,0.001,0.0001 training.batch_size=32,64
```
This will launch 3x2 = 6 individual experiment runs.

Refer to the [Hydra documentation](https://hydra.cc/docs/intro/) for more advanced usage, including different sweepers (like Optuna, which is pre-configured) and complex configuration patterns.

## Output

By default, Hydra creates an `outputs` directory (relative to where you run the script) for each run. Inside this, it further creates subdirectories based on the date and time of the run (e.g., `outputs/YYYY-MM-DD/HH-MM-SS/`). Each run directory will typically contain:

*   `.hydra/`: A directory containing the full configuration (`config.yaml`), overrides (`overrides.yaml`), and a Hydra log file.
*   Log files generated by the configured logger (e.g., if `FileLogger` is used).
*   Model checkpoints saved by the persister.

The exact structure and content of the output directory can be further customized via Hydra and the specific logging/persistence configurations.

## `train_model.py`

The script `simplexity/train_model.py` operates very similarly to `run_experiment.py`. The primary difference is that it defaults to using `simplexity/configs/train_model.yaml` as its base configuration. All command-line overrides and multi-run functionalities apply to it in the same way.

Choose `run_experiment.py` if you intend to use the full experiment setup, potentially including evaluation or more complex workflows defined in `experiment.yaml`. Use `train_model.py` if you are focused solely on the training aspect with a potentially simpler or different default configuration via `train_model.yaml`. 