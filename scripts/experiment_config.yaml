global_config:
  output_dir: "./results"
  device: mps
  wandb: true
  wandb_project: "test_sweep"

train_config:
  batches_per_epoch: 100
  bos: false
  n_epochs: 10

model_config:
  n_ctx: 9
  n_heads: 2
  act_fn: "relu"
  normalization_type: "LN"
  attn_only: false
  seed: 42
  dtype: float32
  #d_model: 64, set automatically based on d_head and n_layers = d_head * n_heads
  #d_mlp: 256, set automatically to 4 * d_model
  #d_vocab: 3, set automatically based on process
  #device: "mps", set automatically based on global_config

sweep_config:
  train_config:
    learning_rate:
      - 1.0e-4
    batch_size:
      - 512
  model_config:
    d_head:
      - 8
    n_layers:
      - 1
      #- 2
      #- 4
      #- 8
      #- 12
    n_heads:
      #- 1
      #- 2
      - 4
      #- 8
  process_config:
    #- name: "post_quantum"
      #alpha: 1.0
      #beta: 1.0
    #- name: "tom_quantum"
      #alpha: 1.5
      #beta: 0.5
    - name: "fanizza"
      alpha: 2000.
      lamb: 0.49
    - name: "rrxor"
      pR1: 0.5
      pR2: 0.5
    #- name: "mess3"
      #x: 0.2
      #a: 0.7

# Optional: You can specify a run_id here, or let it be generated automatically
# run_id: "experiment_001"
