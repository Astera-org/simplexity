---
description: Training loops, optimizers, gradient accumulation, and training best practices
keywords: [training, optimizers, optax, gradient accumulation, early stopping, performance]
use_when: Modifying training behavior, debugging training issues, optimizing training performance
load_priority: component
---
# Training System

The training system in Simplexity handles model optimization with support for both Equinox and Penzai models.

## Training Configuration

Training behavior is controlled via YAML configs:

```yaml
# configs/training/medium.yaml
num_epochs: 50
batch_size: 32
sequence_length: 128
batches_per_epoch: 100

optimizer:
  instance:
    _target_: optax.adam
    learning_rate: 0.001

gradient_clip_norm: 1.0
```

## Training Functions

### Equinox Models

Located in `simplexity/training/train_equinox_model.py`:

```python
def train(
    model: PredictiveModel,
    cfg: TrainingConfig,
    data_generator: GenerativeProcess,
    logger: Logger,
    validation_cfg: Optional[EvaluationConfig] = None,
    validation_generator: Optional[GenerativeProcess] = None,
    persister: Optional[ModelPersister] = None,
) -> tuple[PredictiveModel, float]:
    """Train an Equinox model."""
```

Key features:
- Automatic differentiation with JAX
- Gradient clipping
- Learning rate scheduling
- Checkpoint saving
- Validation during training

### Penzai Models

Located in `simplexity/training/train_penzai_model.py`:

```python
def train(
    model: pz.nn.Layer,
    cfg: TrainingConfig,
    # ... same signature
) -> tuple[pz.nn.Layer, float]:
    """Train a Penzai model."""
```

Differences:
- Uses Penzai's parameter handling
- Different state management
- Penzai-specific optimizations

## Training Loop Structure

### 1. Initialization

```python
# Initialize optimizer
optimizer = instantiate(cfg.optimizer.instance)

# Get model parameters
model_with_state, params = eqx.partition(model, eqx.is_array)

# Initialize optimizer state
opt_state = optimizer.init(params)

# Setup data generation
key = jax.random.PRNGKey(cfg.seed)
```

### 2. Training Step

```python
@eqx.filter_jit
def train_step(params, model_with_state, batch_obs, opt_state):
    # Define loss function
    def loss_fn(params):
        model = eqx.combine(params, model_with_state)
        logits = model(batch_obs[:, :-1])
        targets = batch_obs[:, 1:]
        
        # Cross-entropy loss
        loss = optax.softmax_cross_entropy_with_integer_labels(
            logits, targets
        ).mean()
        return loss
    
    # Compute gradients
    loss, grads = eqx.filter_value_and_grad(loss_fn)(params)
    
    # Clip gradients
    if cfg.gradient_clip_norm:
        grads = optax.clip_by_global_norm(cfg.gradient_clip_norm)(grads)
    
    # Update parameters
    updates, opt_state = optimizer.update(grads, opt_state, params)
    params = optax.apply_updates(params, updates)
    
    return params, opt_state, loss
```

### 3. Epoch Loop

```python
for epoch in range(cfg.num_epochs):
    epoch_losses = []
    
    for batch_idx in range(cfg.batches_per_epoch):
        # Generate batch
        key, subkey = jax.random.split(key)
        batch_obs = generate_batch(
            data_generator, 
            cfg.batch_size,
            cfg.sequence_length,
            subkey
        )
        
        # Training step
        params, opt_state, loss = train_step(
            params, model_with_state, batch_obs, opt_state
        )
        
        epoch_losses.append(loss)
    
    # Log metrics
    avg_loss = np.mean(epoch_losses)
    logger.log_metrics({"train/loss": avg_loss}, step=epoch)
    
    # Validation
    if validation_generator:
        val_loss = evaluate(model, validation_cfg, validation_generator)
        logger.log_metrics({"val/loss": val_loss}, step=epoch)
    
    # Checkpointing
    if persister and (epoch + 1) % cfg.checkpoint_every == 0:
        persister.save_checkpoint(model, epoch + 1)
```

## Optimizer Configuration

### Basic Optimizers

```yaml
# Adam
optimizer:
  instance:
    _target_: optax.adam
    learning_rate: 0.001
    b1: 0.9
    b2: 0.999

# SGD with momentum
optimizer:
  instance:
    _target_: optax.sgd
    learning_rate: 0.01
    momentum: 0.9

# AdamW
optimizer:
  instance:
    _target_: optax.adamw
    learning_rate: 0.001
    weight_decay: 0.01
```

### Learning Rate Schedules

```yaml
# Cosine annealing
optimizer:
  instance:
    _target_: optax.chain
    transforms:
      - _target_: optax.cosine_onecycle_schedule
        transition_steps: ${eval:${training.num_epochs} * ${training.batches_per_epoch}}
        peak_value: 0.001
        pct_start: 0.1
      - _target_: optax.adam
```

### Composite Optimizers

```yaml
# Gradient clipping + Adam
optimizer:
  instance:
    _target_: optax.chain
    transforms:
      - _target_: optax.clip_by_global_norm
        max_norm: 1.0
      - _target_: optax.adam
        learning_rate: 0.001
```

## Advanced Training Patterns

### 1. Custom Loss Functions

```python
def create_custom_loss(alpha=0.1):
    def loss_fn(logits, targets, model):
        # Standard cross-entropy
        ce_loss = optax.softmax_cross_entropy_with_integer_labels(
            logits, targets
        ).mean()
        
        # Add regularization
        l2_loss = sum(
            jnp.sum(x**2) 
            for x in jax.tree_leaves(model) 
            if eqx.is_array(x)
        )
        
        return ce_loss + alpha * l2_loss
    
    return loss_fn
```

### 2. Gradient Accumulation

```python
def train_with_accumulation(model, cfg, accumulation_steps=4):
    accumulated_grads = jax.tree_map(jnp.zeros_like, params)
    
    for step in range(accumulation_steps):
        # Compute gradients
        _, grads = eqx.filter_value_and_grad(loss_fn)(params)
        
        # Accumulate
        accumulated_grads = jax.tree_map(
            lambda a, g: a + g / accumulation_steps,
            accumulated_grads, grads
        )
    
    # Update with accumulated gradients
    updates, opt_state = optimizer.update(
        accumulated_grads, opt_state, params
    )
    params = optax.apply_updates(params, updates)
```

### 3. Early Stopping

```python
def train_with_early_stopping(
    model, cfg, patience=10, min_delta=0.001
):
    best_val_loss = float('inf')
    patience_counter = 0
    
    for epoch in range(cfg.num_epochs):
        # ... training code ...
        
        val_loss = evaluate(model, validation_cfg, validation_generator)
        
        if val_loss < best_val_loss - min_delta:
            best_val_loss = val_loss
            patience_counter = 0
            best_model = model
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            print(f"Early stopping at epoch {epoch}")
            break
    
    return best_model
```

### 4. Mixed Precision Training

```python
from jax import numpy as jnp
import jax

def setup_mixed_precision():
    # Enable mixed precision
    jax.config.update("jax_enable_x64", False)
    
    # Create policy
    policy = jax.tree_map(
        lambda x: x.astype(jnp.float16) if eqx.is_array(x) else x,
        model
    )
    
    return policy

# In training loop
def loss_fn(params):
    model = eqx.combine(params, model_with_state)
    # Cast inputs to float16
    inputs_fp16 = inputs.astype(jnp.float16)
    logits = model(inputs_fp16)
    # Cast back for loss computation
    logits_fp32 = logits.astype(jnp.float32)
    return compute_loss(logits_fp32, targets)
```

## Debugging Training

### 1. Loss Monitoring

```python
def diagnose_training(losses):
    print(f"Initial loss: {losses[0]:.4f}")
    print(f"Final loss: {losses[-1]:.4f}")
    print(f"Min loss: {min(losses):.4f}")
    print(f"Max loss: {max(losses):.4f}")
    
    # Check for NaN
    if any(np.isnan(l) for l in losses):
        print("WARNING: NaN detected in losses!")
    
    # Check for explosion
    if max(losses) > 10 * losses[0]:
        print("WARNING: Loss explosion detected!")
```

### 2. Gradient Analysis

```python
def analyze_gradients(grads):
    grad_norms = jax.tree_map(
        lambda g: jnp.linalg.norm(g.flatten()),
        grads
    )
    
    print("Gradient norms by layer:")
    for path, norm in jax.tree_flatten_with_path(grad_norms)[0]:
        print(f"  {path}: {norm:.6f}")
    
    # Check for vanishing gradients
    total_norm = jnp.sqrt(
        sum(n**2 for n in jax.tree_leaves(grad_norms))
    )
    print(f"Total gradient norm: {total_norm:.6f}")
```

### 3. Learning Rate Debugging

```python
def log_learning_rate(optimizer, opt_state, epoch):
    # Extract current learning rate
    if hasattr(optimizer, 'learning_rate'):
        lr = optimizer.learning_rate
    else:
        # For scheduled optimizers
        lr = opt_state.hyperparams['learning_rate']
    
    logger.log_metrics({"train/learning_rate": lr}, step=epoch)
```

## Performance Optimization

### 1. Data Loading

```python
# Prefetch data
def create_data_iterator(generator, batch_size, seq_len, key):
    def data_gen():
        while True:
            key, subkey = jax.random.split(key)
            yield generate_batch(generator, batch_size, seq_len, subkey)
    
    # Prefetch batches
    return itertools.islice(data_gen(), cfg.batches_per_epoch)
```

### 2. JIT Compilation

```python
# Compile training step
train_step = eqx.filter_jit(train_step)

# Compile evaluation
evaluate = eqx.filter_jit(evaluate)
```

### 3. Device Management

```python
# Ensure model on correct device
def to_device(model, device):
    return jax.tree_map(
        lambda x: jax.device_put(x, device),
        model
    )

# Multi-GPU training
devices = jax.devices()
if len(devices) > 1:
    # Replicate model
    model = jax.tree_map(
        lambda x: jax.device_put_replicated(x, devices),
        model
    )
```

## Common Issues and Solutions

### 1. Gradient Explosion

**Symptoms**: Loss becomes NaN, huge gradient norms

**Solutions**:
- Reduce learning rate
- Enable gradient clipping
- Check initialization
- Use gradient norm logging

### 2. Slow Convergence

**Symptoms**: Loss decreases very slowly

**Solutions**:
- Increase learning rate
- Use adaptive optimizers (Adam)
- Check data generation
- Increase model capacity

### 3. Overfitting

**Symptoms**: Training loss decreases but validation loss increases

**Solutions**:
- Add regularization
- Reduce model size
- Increase data diversity
- Use dropout (if supported)

### 4. Memory Issues

**Symptoms**: OOM errors

**Solutions**:
- Reduce batch size
- Use gradient accumulation
- Enable gradient checkpointing
- Use mixed precision

## Best Practices

1. **Always validate**: Run validation every epoch
2. **Save checkpoints**: Regular checkpointing prevents data loss
3. **Monitor metrics**: Track loss, gradients, and learning rate
4. **Use deterministic seeds**: For reproducibility
5. **Start small**: Test with small models/data first
6. **Profile performance**: Use JAX profiler for bottlenecks
