{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import itertools\n",
                "import timeit\n",
                "from collections.abc import Iterable, Iterator\n",
                "from pathlib import Path\n",
                "\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "\n",
                "from simplexity.generative_processes.builder import build_generalized_hidden_markov_model, build_hidden_markov_model\n",
                "from simplexity.generative_processes.generative_process import GenerativeProcess"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert jax.default_backend() == \"gpu\"\n",
                "print(jax.devices())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "repo_dir = Path().absolute().parent\n",
                "benchmark_data_dir = repo_dir / \"data/benchmark_generate\"\n",
                "if not benchmark_data_dir.exists():\n",
                "    benchmark_data_dir.mkdir()\n",
                "print(benchmark_data_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_observations(\n",
                "    process: GenerativeProcess,\n",
                "    initial_state: jax.Array,\n",
                "    sequence_len: int,\n",
                "    batch_size: int,\n",
                "    num_batches: int,\n",
                ") -> Iterator[jax.Array]:\n",
                "    \"\"\"Yields batches of observations generated from a generative process.\"\"\"\n",
                "    key = jax.random.PRNGKey(0)\n",
                "    states = jnp.repeat(initial_state[None, :], batch_size, axis=0)\n",
                "    for _ in range(num_batches):\n",
                "        key, batch_key = jax.random.split(key)\n",
                "        batch_keys = jax.random.split(batch_key, batch_size)\n",
                "        states, batch_observations = process.generate(states, batch_keys, sequence_len)\n",
                "        yield batch_observations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def test_generate_shape(\n",
                "    process: GenerativeProcess,\n",
                "    initial_state: jax.Array,\n",
                "    sequence_len: int,\n",
                "    batch_size: int,\n",
                "    num_batches: int ,\n",
                ") -> None:\n",
                "    \"\"\"Simple test of the generate function.\"\"\"\n",
                "    observations = jnp.stack(list(generate_observations(process, initial_state, sequence_len, batch_size, num_batches)))\n",
                "    assert observations.shape == (num_batches, batch_size, sequence_len)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_generate(\n",
                "    process: GenerativeProcess,\n",
                "    initial_state: jax.Array,\n",
                "    sequence_len: int,\n",
                "    batch_size: int,\n",
                "    num_batches: int,\n",
                "    num_runs: int = 1,\n",
                ") -> float:\n",
                "    \"\"\"Get the average time it takes to generate a batch of observations.\"\"\"\n",
                "\n",
                "    def run_generate():\n",
                "        for _ in generate_observations(process, initial_state, sequence_len, batch_size, num_batches):\n",
                "            pass\n",
                "\n",
                "    return timeit.timeit(run_generate, number=num_runs) / (num_batches * num_runs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_benchmark_results(\n",
                "    process: GenerativeProcess,\n",
                "    initial_state: jax.Array,\n",
                "    num_batches: int,\n",
                "    log2_sequence_lengths: Iterable[int] = range(2, 12),\n",
                "    log2_batch_sizes: Iterable[int] = range(5),\n",
                ") -> pd.DataFrame:\n",
                "    \"\"\"Get benchmark results for different combinations of sequence lengths and batch sizes.\"\"\"\n",
                "    data = []\n",
                "    for log2_sequence_len, log2_batch_size in itertools.product(log2_sequence_lengths, log2_batch_sizes):\n",
                "        sequence_len = 2**log2_sequence_len\n",
                "        batch_size = 2**log2_batch_size\n",
                "        time = time_generate(process, initial_state, sequence_len, batch_size, num_batches)\n",
                "        data.append({\"sequence_len\": sequence_len, \"batch_size\": batch_size, \"time_per_batch\": time})\n",
                "\n",
                "    return pd.DataFrame.from_records(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_benchmark_results(df: pd.DataFrame, model_name: str, num_batches: int) -> None:\n",
                "    \"\"\"Plot benchmark results.\"\"\"\n",
                "    sequence_lengths = sorted(df[\"sequence_len\"].unique().tolist())\n",
                "    _, ax = plt.subplots()\n",
                "    for batch_size, group in df.groupby(\"batch_size\"):\n",
                "        ax.semilogx(group[\"sequence_len\"], group[\"time_per_batch\"], label=f\"batch_size={batch_size}\", marker=\"o\")\n",
                "    ax.legend()\n",
                "    ax.minorticks_off()\n",
                "    ax.set_xticks(sequence_lengths)\n",
                "    ax.set_xticklabels(sequence_lengths)\n",
                "    ax.set_xlabel(\"Sequence Length\")\n",
                "    ax.set_ylabel(\"Time per batch (s)\")\n",
                "    ax.set_title(f\"{model_name}, ({num_batches=})\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def benchmark(\n",
                "    model: GenerativeProcess,\n",
                "    initial_state: jax.Array,\n",
                "    model_name: str,\n",
                "    num_batches: int = 16,\n",
                "    results_dir: Path = benchmark_data_dir,\n",
                ") -> None:\n",
                "    \"\"\"Run a series of benchmark trials for the generative function, plot and save the results.\"\"\"\n",
                "    test_generate_shape(model, initial_state, sequence_len=3, batch_size=2, num_batches=4)\n",
                "    path = results_dir / f\"{model_name}_generate_benchmark.csv\"\n",
                "    if path.exists():\n",
                "        df = pd.read_csv(path)\n",
                "    else:\n",
                "        df = get_benchmark_results(model, initial_state, num_batches)\n",
                "        df.to_csv(path, index=False)\n",
                "    plot_benchmark_results(df, model_name, num_batches)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmm = build_hidden_markov_model(\"days_of_week\")\n",
                "initial_state = hmm.stationary_state\n",
                "benchmark(hmm, initial_state, \"days_of_week\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmm = build_hidden_markov_model(\"even_ones\", p=0.5)\n",
                "initial_state = hmm.stationary_state\n",
                "benchmark(hmm, initial_state, \"even_ones\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ghmm = build_generalized_hidden_markov_model(\"fanizza\", alpha=2000, lamb=0.49)\n",
                "initial_state = ghmm.stationary_state\n",
                "benchmark(ghmm, initial_state, \"fanizza\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmm = build_hidden_markov_model(\"mess3\", a=0.6, x=0.15)\n",
                "initial_state = hmm.stationary_state\n",
                "benchmark(hmm, initial_state, \"mess3\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmm = build_hidden_markov_model(\"no_consecutive_ones\", p=0.5)\n",
                "initial_state = hmm.stationary_state\n",
                "benchmark(hmm, initial_state, \"no_consecutive_ones\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ghmm = build_generalized_hidden_markov_model(\"post_quantum\", log_alpha=1.0, beta=0.5)\n",
                "initial_state = ghmm.stationary_state\n",
                "benchmark(ghmm, initial_state, \"post_quantum\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmm = build_hidden_markov_model(\"rrxor\", pR1=0.5, pR2=0.5)\n",
                "initial_state = hmm.stationary_state\n",
                "benchmark(hmm, initial_state, \"rrxor\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ghmm = build_generalized_hidden_markov_model(\"tom_quantum\", alpha=1.0, beta=1.0)\n",
                "initial_state = ghmm.stationary_state\n",
                "benchmark(ghmm, initial_state, \"tom_quantum\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmm = build_hidden_markov_model(\"zero_one_random\", p=0.5)\n",
                "initial_state = hmm.stationary_state\n",
                "benchmark(hmm, initial_state, \"zero_one_random\")"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
