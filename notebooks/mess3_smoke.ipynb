{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mess3 generator smoke test\n",
        "\n",
        "This notebook builds a simple `mess3` hidden Markov model and prints a few generated symbols.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated observations: [0, 2, 0, 2, 2, 0, 0, 1, 2, 1]\n"
          ]
        }
      ],
      "source": [
        "# pyright: reportMissingImports=false\n",
        "import jax\n",
        "\n",
        "from simplexity.generative_processes.builder import build_hidden_markov_model\n",
        "\n",
        "# Instantiate mess3 with defaults from config (x=0.15, a=0.6)\n",
        "model = build_hidden_markov_model(\"mess3\", x=0.15, a=0.6)\n",
        "\n",
        "# Initial belief state: use the model's normalizing_eigenvector as a valid distribution\n",
        "state = model.normalizing_eigenvector[None, :]\n",
        "\n",
        "# Generate a short sequence\n",
        "key = jax.random.PRNGKey(0)[None, :]\n",
        "sequence_len = 10\n",
        "final_state, observations = model.generate(state, key, sequence_len, False)\n",
        "\n",
        "print(\"Generated observations:\", observations.squeeze().tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=00 obs=0 belief=[0.3333333432674408, 0.3333333432674408, 0.3333333432674408]\n",
            "t=01 obs=2 belief=[0.6000000238418579, 0.20000000298023224, 0.20000000298023224]\n",
            "t=02 obs=0 belief=[0.31578949093818665, 0.17105263471603394, 0.5131579041481018]\n",
            "t=03 obs=2 belief=[0.5894569158554077, 0.14816294610500336, 0.2623802125453949]\n",
            "t=04 obs=2 belief=[0.2984992265701294, 0.145717591047287, 0.555783212184906]\n",
            "t=05 obs=0 belief=[0.16437214612960815, 0.12040877342224121, 0.7152190804481506]\n",
            "t=06 obs=0 belief=[0.4870404005050659, 0.14601799845695496, 0.36694154143333435]\n",
            "t=07 obs=1 belief=[0.6828927993774414, 0.12545859813690186, 0.19164860248565674]\n",
            "t=08 obs=2 belief=[0.365500271320343, 0.456887811422348, 0.17761191725730896]\n",
            "t=09 obs=1 belief=[0.23474085330963135, 0.26835331320762634, 0.4969058632850647]\n"
          ]
        }
      ],
      "source": [
        "# pyright: reportMissingImports=false\n",
        "# Generate again but keep all intermediate belief states (priors)\n",
        "states_per_step, obs = model.generate(state, key, sequence_len, True)\n",
        "\n",
        "# Normalize belief states to probabilities per step\n",
        "beliefs = jax.vmap(model.normalize_belief_state)(states_per_step.squeeze(0))\n",
        "\n",
        "for t, (o, b) in enumerate(zip(obs.squeeze(0).tolist(), beliefs.tolist())):\n",
        "\tprint(f\"t={t:02d} obs={o} belief={b}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Product observations (tuples): [(0, 1), (2, 2), (0, 0), (2, 0), (2, 1), (0, 2), (0, 1), (1, 1), (2, 0), (1, 1)]\n",
            "t=00 obs=(0, 1) belief_dim=9\n",
            "t=01 obs=(2, 2) belief_dim=9\n",
            "t=02 obs=(0, 0) belief_dim=9\n",
            "t=03 obs=(2, 0) belief_dim=9\n",
            "t=04 obs=(2, 1) belief_dim=9\n",
            "t=05 obs=(0, 2) belief_dim=9\n",
            "t=06 obs=(0, 1) belief_dim=9\n",
            "t=07 obs=(1, 1) belief_dim=9\n",
            "t=08 obs=(2, 0) belief_dim=9\n",
            "t=09 obs=(1, 1) belief_dim=9\n"
          ]
        }
      ],
      "source": [
        "# pyright: reportMissingImports=false\n",
        "import itertools\n",
        "import importlib\n",
        "import simplexity.generative_processes.builder as builder\n",
        "\n",
        "# Ensure we see latest symbols if the module changed in this session\n",
        "builder = importlib.reload(builder)\n",
        "\n",
        "# Build a product of two mess3 generators\n",
        "prod_model = builder.build_product_hidden_markov_model(\n",
        "\tprocess_names=[\"mess3\", \"mess3\"],\n",
        "\tprocess_kwargs=[{\"x\": 0.15, \"a\": 0.6}, {\"x\": 0.2, \"a\": 0.5}],\n",
        ")\n",
        "\n",
        "# Initial state for the product model\n",
        "prod_state = prod_model.normalizing_eigenvector[None, :]\n",
        "\n",
        "# Generate a few steps and print observations as tuples and beliefs\n",
        "prod_final_state, prod_obs = prod_model.generate(prod_state, key, sequence_len, False)\n",
        "\n",
        "# Decode product observations back to tuples for readability\n",
        "vocab_sizes = [3, 3]\n",
        "\n",
        "def unravel_index(idx: int, dims: list[int]) -> tuple[int, ...]:\n",
        "\tcoords = []\n",
        "\tfor d in reversed(dims):\n",
        "\t\tcoords.append(idx % d)\n",
        "\t\tidx //= d\n",
        "\treturn tuple(reversed(coords))\n",
        "\n",
        "obs_tuples = [unravel_index(int(o), vocab_sizes) for o in prod_obs.squeeze(0).tolist()]\n",
        "print(\"Product observations (tuples):\", obs_tuples)\n",
        "\n",
        "# Now with all states and beliefs\n",
        "prod_states_per_step, prod_obs_all = prod_model.generate(prod_state, key, sequence_len, True)\n",
        "prod_beliefs = jax.vmap(prod_model.normalize_belief_state)(prod_states_per_step.squeeze(0))\n",
        "\n",
        "for t, (o, b) in enumerate(zip(prod_obs_all.squeeze(0).tolist(), prod_beliefs.tolist())):\n",
        "\tprint(f\"t={t:02d} obs={unravel_index(int(o), vocab_sizes)} belief_dim={len(b)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 timesteps of beliefs (joint vs. factored marginals):\n",
            "t=00 joint_len=9 marg1=[0.3330000042915344, 0.3330000042915344, 0.3330000042915344] marg2=[0.3330000042915344, 0.3330000042915344, 0.3330000042915344]\n",
            "t=01 joint_len=9 marg1=[0.6000000238418579, 0.20000000298023224, 0.20000000298023224] marg2=[0.25, 0.5, 0.25]\n",
            "t=02 joint_len=9 marg1=[0.3160000145435333, 0.17100000381469727, 0.5130000114440918] marg2=[0.23100000619888306, 0.30800002813339233, 0.4620000123977661]\n",
            "t=03 joint_len=9 marg1=[0.5890000462532043, 0.14800000190734863, 0.26200002431869507] marg2=[0.4520000219345093, 0.25, 0.2980000078678131]\n",
            "t=04 joint_len=9 marg1=[0.2980000078678131, 0.14600001275539398, 0.5560000538825989] marg2=[0.5520000457763672, 0.21700000762939453, 0.23100000619888306]\n"
          ]
        }
      ],
      "source": [
        "# pyright: reportMissingImports=false\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# For mess3 components, each has 3 hidden states\n",
        "state_sizes = [3, 3]\n",
        "\n",
        "# beliefs over joint space: shape (T, prod(state_sizes)) already computed as prod_beliefs\n",
        "\n",
        "def factor_marginals(belief_1d: jnp.ndarray, dims: list[int]) -> list[jnp.ndarray]:\n",
        "\t\"\"\"Return per-component marginal beliefs from a joint belief vector.\"\"\"\n",
        "\ttensor = belief_1d.reshape(dims)\n",
        "\tmargs: list[jnp.ndarray] = []\n",
        "\tfor i in range(len(dims)):\n",
        "\t\taxes = tuple(ax for ax in range(len(dims)) if ax != i)\n",
        "\t\tmargs.append(tensor.sum(axis=axes))\n",
        "\treturn margs\n",
        "\n",
        "print(\"First 5 timesteps of beliefs (joint vs. factored marginals):\")\n",
        "for t in range(min(5, prod_beliefs.shape[0])):\n",
        "\tjoint = prod_beliefs[t]\n",
        "\tm1, m2 = factor_marginals(joint, state_sizes)\n",
        "\tprint(\n",
        "\t\tf\"t={t:02d} joint_len={joint.shape[0]} marg1={jnp.round(m1, 3).tolist()} marg2={jnp.round(m2, 3).tolist()}\"\n",
        "\t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (851720826.py, line 18)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcm_joint = cm.get_cmap(\"viridis\")\\ncm_resid = cm.get_cmap(\"coolwarm\")\u001b[39m\n                                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "# pyright: reportMissingImports=false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import TwoSlopeNorm, Normalize\n",
        "import jax.numpy as jnp\n",
        "\n",
        "plt.rcParams.update({\n",
        "\t\"figure.figsize\": (12, 4),\n",
        "\t\"axes.titlesize\": 12,\n",
        "\t\"axes.labelsize\": 11,\n",
        "\t\"xtick.labelsize\": 9,\n",
        "\t\"ytick.labelsize\": 9,\n",
        "})\n",
        "\n",
        "# Only supports 2 components for the heatmap view\n",
        "assert len(state_sizes) == 2, \"Heatmap viz assumes two components\"\n",
        "\n",
        "cm_joint = cm.get_cmap(\"viridis\")\n",
        "cm_resid = cm.get_cmap(\"coolwarm\")\n",
        "\n",
        "\n",
        "def outer_from_marginals(marginals: list[np.ndarray]) -> np.ndarray:\n",
        "\tmat = np.outer(marginals[0], marginals[1])\n",
        "\treturn mat\n",
        "\n",
        "\n",
        "def plot_belief_triptych(joint_vec: np.ndarray, dims: list[int], annotate: bool = False):\n",
        "\tm1, m2 = factor_marginals(jnp.asarray(joint_vec), dims)\n",
        "\tJ = joint_vec.reshape(dims)\n",
        "\tF = outer_from_marginals([np.asarray(m1), np.asarray(m2)])\n",
        "\tR = J - F\n",
        "\n",
        "\tvmax = max(J.max(), F.max())\n",
        "\trmax = np.max(np.abs(R))\n",
        "\n",
        "\tfig, axes = plt.subplots(1, 3, figsize=(13, 4), constrained_layout=True)\n",
        "\tfor ax, data, title, cmap, norm in [\n",
        "\t\t(axes[0], J, \"Joint belief P(S1,S2)\", cm_joint, Normalize(vmin=0, vmax=vmax)),\n",
        "\t\t(axes[1], F, \"Factored outer product P(S1)⊗P(S2)\", cm_joint, Normalize(vmin=0, vmax=vmax)),\n",
        "\t\t(axes[2], R, \"Residual (Joint - Factored)\", cm_resid, TwoSlopeNorm(vcenter=0, vmin=-rmax, vmax=rmax)),\n",
        "\t]:\n",
        "\t\tim = ax.imshow(data, cmap=cmap, norm=norm)\n",
        "\t\tax.set_xlabel(\"S2\")\n",
        "\t\tax.set_ylabel(\"S1\")\n",
        "\t\tax.set_xticks(range(dims[1]))\n",
        "\t\tax.set_yticks(range(dims[0]))\n",
        "\t\tax.set_title(title)\n",
        "\t\tcbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\t\tif annotate:\n",
        "\t\t\tfor i in range(dims[0]):\n",
        "\t\t\t\tfor j in range(dims[1]):\n",
        "\t\t\t\t\tax.text(j, i, f\"{data[i, j]:.2f}\", ha=\"center\", va=\"center\", fontsize=8, color=\"white\" if np.abs(data[i, j]) > (norm.vmax if hasattr(norm, 'vmax') else rmax)/2 else \"black\")\n",
        "\treturn fig\n",
        "\n",
        "\n",
        "def kl_divergence(p: np.ndarray, q: np.ndarray, eps: float = 1e-12) -> float:\n",
        "\tp = p.astype(float)\n",
        "\tq = q.astype(float)\n",
        "\tp = np.clip(p, eps, 1.0)\n",
        "\tq = np.clip(q, eps, 1.0)\n",
        "\tp /= p.sum()\n",
        "\tq /= q.sum()\n",
        "\treturn float(np.sum(p * (np.log(p) - np.log(q))))\n",
        "\n",
        "\n",
        "def plot_factorization_error_over_time(beliefs: np.ndarray, dims: list[int]):\n",
        "\tkls: list[float] = []\n",
        "\tfor t in range(beliefs.shape[0]):\n",
        "\t\tm1, m2 = factor_marginals(jnp.asarray(beliefs[t]), dims)\n",
        "\t\tfactored = outer_from_marginals([np.asarray(m1), np.asarray(m2)]).reshape(-1)\n",
        "\t\tkls.append(kl_divergence(beliefs[t], factored))\n",
        "\tfig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
        "\tax.plot(kls, marker=\"o\", lw=1.5)\n",
        "\tax.set_title(\"KL(P_joint || P1⊗P2) over time\")\n",
        "\tax.set_xlabel(\"timestep\")\n",
        "\tax.set_ylabel(\"KL divergence\")\n",
        "\tax.grid(True, alpha=0.3)\n",
        "\treturn fig\n",
        "\n",
        "# Demo for a single timestep (e.g., t=0) and the time series of errors\n",
        "_ = plot_belief_triptych(prod_beliefs[0], state_sizes, annotate=True)\n",
        "_ = plot_factorization_error_over_time(prod_beliefs, state_sizes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
